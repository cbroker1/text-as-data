{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. In a few paragraphs, explain when and why dictionaries successfully measure that which they attempt to measure, when they do not, and the possible risks of analyzing text with dictionaries.\n",
    "\n",
    "\n",
    "\n",
    "Why dictionaries successfully measure things. \n",
    "\n",
    "    Dictionaries successfully classify a document through the mathematical process of applying measurable relationships between words and their associated classes. Both approaches, let it be using per-existing relationships (ie weights) or generating new ones, take what's known about a group of documents (classified documents) and apply that knowledge to a set of new documents (unclassified documents). Thousands, if not tens of thousands, of relationships are applied to each new document individually - all that knowledge, applied to each new document - is what makes this form of classification powerful.\n",
    "    So why do they successfully measure things..\n",
    "\n",
    "\n",
    "Problems with Dictionaries.\n",
    "\n",
    "    As discussed in the lecture @15:37, \"dictionaries are context invariant\". Thus begs the questions, what determines one context different from another and, a bit more interesting, to what extent can a dictionary be used outside of its original context? How do we know when it cannot be used? \n",
    "    As I was thinking about these questions I recalled a youtube video I watched from a couple days ago on another COVID-resultant youtube binge of mine to kill some time: https://www.youtube.com/watch?v=oAbQEVmvm8Y \n",
    "    In the video the speaker showcases how data scientists are using datasets from different domains, together, to solve one specific problem. That got me wondering, are there absolute bounds to which a dictionary can be used in solving a problem? The starry eyed Elon Musk in me says no, no way (wave arms magically and say, \"there's infinite possibilities\") but the practical side of me says yes. As there's no such thing as infinate gpu memory.  \n",
    "    In the example used in the lecture ~@18:00 surrounding the word 'Hopkins'. Agreed, this dictionary should not be used to explore sentiment-relationships between Hopkins and, let's say, the public. So then what should we use? Thinking off the cuff here, after living in Baltimore for 6 years, downtown, I can say for 99% certainty there are communities in Baltimore that do not like Hopkins. Period. On the other hand, its students, well, we like Hopkins quite a bit. For every one that dislikes/likes Hopkins there’s 2 that are indifferent. \n",
    "    So, in my opinion, we’d need to find a balance between the two extremes if we wanted to generate a dictionary surrounding sentiment and Hopinks. This balance would also need to be representative of the population to which the impending results would be applied to. I suppose there's seeminlingly an infinate amount of things one could do to create the 'perfect' dictionary. (It would be kind of fun to generate a dictionary such as this, one that's evenly distributed, to use to monitor FB/Insta/Twitter feeds.) From a development standpoint it would be interesting to see how generating a new model, then adding more training data to it, would work in a production enviornament.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using a dictionary in qdapDictionaries, conduct sentiment analysis on your corpus. Write up the results in a pdf and interpret them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the answers to both assignment questions in a single pdf. file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os as os\n",
    "import sys as sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "#torch goodness\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#huggingface goodness\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "#set graph config\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "\n",
    "#set seed\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "#check gpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imdb from http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "#\"We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing.\"\n",
    "#this file was larger than 100mb (github's file size limit)\n",
    "df_imdb = pd.read_csv('imdb.csv')\n",
    "\n",
    "#https://www.kaggle.com/lava18/google-play-store-apps\n",
    "#google play app reviews ~16k\n",
    "df_google = pd.read_csv(\"reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crystal Feel http://www.crystalfeel.socialanalyticsplus.net/ \n",
    "Crystal Feel Manual http://52.3.21.155/crystalfeel/[CrystalFeel]_User_Manual.pdf\n",
    "Super Cool App Thingy https://medium.com/@mirzamujtaba10/sentiment-analysis-642b935ab6f9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-as-data",
   "language": "python",
   "name": "text-as-dada"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
