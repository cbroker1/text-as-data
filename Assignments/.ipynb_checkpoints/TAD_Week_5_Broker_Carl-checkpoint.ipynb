{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. In a few paragraphs, explain when and why dictionaries successfully measure that which they attempt to measure, when they do not, and the possible risks of analyzing text with dictionaries.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Problems with Dictionaries:\n",
    "\n",
    "    As discussed in the lecture @15:37, \"dictionaries are context invariant\". Thus begs the quesitons, what determines one context different from another and, a bit more interesting, to what extent can a dictionary be used outside of its origional context? How do we know when it cannot be used? \n",
    "    As I was thinking about these I recalled a youtube video I watched from a couple days ago, on another COVID-resultant youtube binge of mine, to kill some time.\n",
    "    \n",
    "            https://www.youtube.com/watch?v=oAbQEVmvm8Y \n",
    "\n",
    "    In the video the speaker showcases how data scientists are using datasets from different domains, together, to solve one specific problem. That got me wondering, are there absolute bounds to which a datset can be used (perhaps a dictionary as well) in solving a problem? The starry eyed Elon Musk in me says no, no way (wave arms magically and say, \"there's infinate possiblites\") but the practical side of me says yes. I guess you can use 'anything' as long as validation works out? \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using a dictionary in qdapDictionaries, conduct sentiment analysis on your corpus. Write up the results in a pdf and interpret them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the answers to both assignment questions in a single pdf. file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os as os\n",
    "import sys as sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "#torch goodness\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#huggingface goodness\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "#set graph config\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "\n",
    "#set seed\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "#check gpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imdb from http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "#\"We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing.\"\n",
    "#this file was larger than 100mb (github's file size limit)\n",
    "df_imdb = pd.read_csv('imdb.csv')\n",
    "\n",
    "#https://www.kaggle.com/lava18/google-play-store-apps\n",
    "#google play app reviews ~16k\n",
    "df_google = pd.read_csv(\"reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crystal Feel http://www.crystalfeel.socialanalyticsplus.net/ \n",
    "Crystal Feel Manual http://52.3.21.155/crystalfeel/[CrystalFeel]_User_Manual.pdf\n",
    "Super Cool App Thingy https://medium.com/@mirzamujtaba10/sentiment-analysis-642b935ab6f9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-as-data",
   "language": "python",
   "name": "text-as-dada"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
